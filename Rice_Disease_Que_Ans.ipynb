{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. If the image_size is set to 224x224 pixels, how will an image with dimensions 1000x1000 pixels and another with 50x50 pixels be processed? Will the pixels be cut, or will the image be shrunk without losing the original pixels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- `When resizing, due to the compression of lot of information in the image we will loose some pixels that is details of the image, and when upscaling, there will be no pixel loss instead more pixels will be added, but quality will not be maintained`.\n",
    "\n",
    "-- `However, there is option of resizing and padding but that will loose the quality of image`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Our dataset has all the image in RGB format or not, explain the code line to check.\n",
    "\n",
    "    -- Our all the original images are in RGB, and augemented was saved in BGR which can be changed in RBG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def is_image_bgr(image):\n",
    "    # Select a pixel in the middle of the image\n",
    "    height, width, _ = image.shape\n",
    "    middle_pixel = image[height // 2, width // 2]\n",
    "\n",
    "    # Check the values of the middle pixel\n",
    "    blue, green, red = middle_pixel\n",
    "\n",
    "    # If blue is the highest value, the image is likely in BGR format\n",
    "    if blue > red and blue > green:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Load an image using OpenCV\n",
    "image = cv2.imread('path_of_image.jpg')\n",
    "\n",
    "# Check if the image is in BGR format\n",
    "if is_image_bgr(image):\n",
    "    print(\"The image is in BGR format.\")\n",
    "else:\n",
    "    print(\"The image is in RGB format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How would you explain the purpose of each argument in the ImageDataGenerator function, \n",
    "    such as (rescale, rotation_range, width_shift_range, height_shift_range) ?\n",
    "    Could you also provide more details on how these parameters affect image augmentation and the overall training and testing process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- `It is used for real time data augmentation with this parameters used for the specific augmentation ex: rotating, rescaling etc. and the argument we provide to it like :\n",
    "'width_shift_range=0.2' specifies that the image can be shift horizontally up to 20% of its width.\n",
    "'rescale=1./255' scales pixle values from [0-255] to [0-1]. \n",
    "'rotation_range=40' defines random rotation between +40 and -40.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. How is the train and test split are different from each other if it has same parameters? Check if test split has same images as train or not?\n",
    "\n",
    "    -- `Even if train and test split has same parameters still the images will be differently augmented due to randomness.\n",
    "        To determine whether to use train or test split we have a subset parameter in train/valid generator.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(     save_to_dir=test_save_dir,\n",
    "    save_prefix='test_',\n",
    "    save_format='jpeg'\n",
    ")\n",
    "\n",
    "# Generate and save train images\n",
    "for _ in range(train_generator.samples // train_generator.batch_size):\n",
    "    next(train_generator)\n",
    "\n",
    "# Generate and save validation images\n",
    "for _ in range(validation_generator.samples // validation_generator.batch_size):\n",
    "    next(validation_generator)\n",
    "\n",
    "print(\"Train and test images saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. What is `filter` in conv. layers? what happens when we increase or decrease the value of filters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- `Filter is use to take out the information from specific image (textures, edges, colours).\n",
    "    Increasing more filters will provide more detailed information, improves accuracy and takes out more features from an image.\n",
    "    Decreasing the filters will provide less features of an image, less detailed information and affects on accuracy too.`\n",
    "    ` But using too many filters can lead to overfitting as well.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. What is padding in Conv. layers? why padding='same' is used in our code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- `Padding is used to prevent the loss of image data.`\n",
    "   ` we use padding=same to ensure the same spatial dimensions as the input.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Why we used `use_bias=False`? what is 'use_bias'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- `Bias is a small adjustment which is added to the output of a neuron to help the model learn better .`\n",
    "   ` We used bias as False to reduce the number of parameters and simplify the model, as only the weights will be updated during training.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Explain different layers of CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CNN has following layers :`\n",
    "- Input Layer (Image as input)\n",
    "- Convolutional Layer (Detects Features, Edges, Textures and Patterns)\n",
    "- Max Pooling Layer (To reduce the dimensionality of the feature maps)\n",
    "- Flatten Layer (converts Feature Maps into 1D to feed dense layer)\n",
    "- Dropout Layer (To drop random neurons)\n",
    "- Dense Layer (Fully Connected layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. Explain different parameters used in CNN in our code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input_Shape(224x224x3) - Provides the input image to the neural network.\n",
    "- Filters(kernel) - Filters are used to detect features of a image. the more the filters the more feature detection. but, if data is not large enough then it will lead to overfitting.\n",
    "- Kernel_size(3x3) - It is the dimension of the filter. (3x3) captures fine details.\n",
    "- Padding='same' - It means the input data will be padded with zeroes around the borders.\n",
    "- Stride=1 - It moves the filter one step. which covers every possible position on input image.\n",
    "- Activation='Relu' - It introduces non-linearity into the model, allowing it to learn complex patterns.\n",
    "- use_bias='False' - It means the model will not include this additional parameter in the convolutional layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. How is floor division is different from division?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- `Division gives the result with decimals while floor division gives us Whole number without decimals as a result.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11. What is  `restore_best_weights`? print the code to show best weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- `If True, instructs the model to revert to the weights from the epoch where the mentioned metric was best.`\n",
    "    `If Flase, retains weights from last training epoch.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = model.get_weights()\n",
    "print(\"Best Weights:\", best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. How to identify if the model is overfitting and underfitting and how to handle this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- `Overfitting - When the model performs well on training data but poorly on testing data. when it has high accuracy and much lower val_accuracy and when the loss curve diverge.`\n",
    "    `Underfitting - When the model performs poorly on both training and testing data. and when both losses are similiar or high.`\n",
    "\n",
    "-- To handle overfitting we can use : \n",
    "1. Data Augmentation \n",
    "2. Regularization (L1/L2), Dropout layer\n",
    "3. Early Stopping\n",
    "\n",
    "-- To handle underfitting we can : \n",
    "1. Increase no. of filters/layers\n",
    "2. Use complex architectures or pre-trained model\n",
    "3. Increase the epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13. Explain this code and why it is used here?\n",
    "      \"img_array = np.expand_dims(img_array, axis=0)\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- It is used to add an extra dimension to an array\n",
    "`np.expand_dims` - This function adds a new dimension to the array at a specifies position.\n",
    "`img_array` - It is a shape of image (height, width, channel) after executing this code (1,h,w,c).\n",
    "`axis=0` - It tells the new dimension is added at the beginning of the shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q14. Explain this code why it is used?\n",
    "     \"predicted_class_index = np.argmax(predictions, axis=1)[0]\",\n",
    "      \"predicted_class_name = class_indices[predicted_class_index]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `predicted_class_index = np.argmax(predictions, axis=1)[0]` - This code essentially finds out which class the model thinks the image belongs to by selecting the class with the highest probability.\n",
    "- `Predictions` - Here it is the probability output of a model in an array. ex : [0.1,0.05,0.85].\n",
    "- `np.argmax()` - This function from numpy lib is used to find the index of the maximum value in an array. ex: 0.85 in above array.\n",
    "- `axis=1` - It the specifies the dimension to find in an array.\n",
    "- `[0]` - It is used to extract single value from an array of output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `predicted_class_name = class_indices[predicted_class_index]` - This code converts the class index obtained in the above code into human-readable classes.\n",
    "- `class_indices` - It usually a dictionary which maps class indices (0,1,2) to class names (cat,dog,car).\n",
    "- `Predicted_class_index` - From previous code takes the index value and returns name associated with it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
